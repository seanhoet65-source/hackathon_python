{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920ef7bb-0e31-4151-9fb0-50de1141d91e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffe1f7f4ada8c4a3160626f214fc1e36",
     "grade": false,
     "grade_id": "cell-48cccda20e73351e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Hackathon: From Raw Data to ML-Ready Dataset\n",
    "## Insight-Driven EDA and End-to-End Feature Engineering on Airbnb Data Using pandas and Plotly\n",
    "\n",
    "### What is a Hackathon?\n",
    "\n",
    "A hackathon is a fast-paced, collaborative event where participants use data and technology to solve a real problem end-to-end.  \n",
    "In this hackathon, you will work with a **real-world Airbnb dataset** and complete two interconnected goals:\n",
    "\n",
    "- Produce a **high-quality exploratory data analysis (EDA)** using `pandas` and `plotly`, extracting meaningful insights, trends, and signals from the data.  \n",
    "- Design and deliver a **clean, feature-rich, ML-ready dataset** that will serve as the foundation for a follow-up hackathon focused on building and evaluating machine learning models.\n",
    "\n",
    "Your task is to **get the most out of the data**: uncover structure and patterns through EDA, and engineer informative features (numerical, categorical, temporal, textual (TF–IDF), and optionally image-based) to maximize the predictive power of the final dataset.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>About the Dataset</b>\n",
    "\n",
    "<u>Context</u>\n",
    "\n",
    "The data comes from <a href=\"https://insideairbnb.com/get-the-data/\">Inside Airbnb</a>, an open project that publishes detailed, regularly updated datasets for cities around the world.  \n",
    "Each city provides three main CSV files:\n",
    "\n",
    "- <b>listings.csv</b> — property characteristics, host profiles, descriptions, amenities, etc.  \n",
    "- <b>calendar.csv</b> — daily availability and pricing information for each listing.  \n",
    "- <b>reviews.csv</b> — guest feedback and textual reviews.\n",
    "\n",
    "These datasets offer a rich view of the short-term rental market, including availability patterns, pricing behavior, host attributes, and guest sentiment.  \n",
    "\n",
    "<u>Inspiration</u>\n",
    "\n",
    "Your ultimate objective is to create a dataset suitable for training a machine learning model that predicts whether a specific Airbnb listing will be <b>available on a given date</b>, using property attributes, review information, and host characteristics.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Task</b>\n",
    "\n",
    "Using one city of your choice from Inside Airbnb, create an end-to-end pipeline that:\n",
    "\n",
    "1. Loads and explores the raw data (EDA).  \n",
    "2. Engineers features (numerical, categorical, temporal, textual TF–IDF, etc.).  \n",
    "3. Builds a unified ML-ready dataset.  \n",
    "\n",
    "Please remember to add comments explaining your decisions. Comments help us understand your thought process and ensure accurate evaluation of your work. This assignment requires code-based solutions—**manually calculated or hard-coded results will not be accepted**. Thoughtful comments and visualizations are encouraged and will be highly valued.\n",
    "\n",
    "- Write your solution directly in this notebook, modifying it as needed.\n",
    "- Once completed, submit the notebook in **.ipynb** format via Moodle.\n",
    "    \n",
    "<b>Collaboration Requirement: Git & GitHub</b>\n",
    "\n",
    "You must collaborate with your team using a **shared GitHub repository**.  \n",
    "Your use of Git is part of the evaluation. We will specifically look at:\n",
    "\n",
    "- Commit quality (clear messages, meaningful steps).  \n",
    "- Balanced participation across team members.  \n",
    "- Use of branches.  \n",
    "- Ability to resolve merge conflicts appropriately.  \n",
    "- A clean, readable project history that reflects real collaboration.\n",
    "\n",
    "Good Git practice is **part of your grade**, not optional.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    You are free to add as many cells as you wish as long as you leave untouched the first one.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Hints</b>\n",
    "\n",
    "- Text columns often carry substantial predictive power, use text-vectorization methods to extract meaningful features.  \n",
    "- Make sure all columns use appropriate data types (categorical, numeric, datetime, boolean). Correct dtypes help prevent subtle bugs and improve performance.  \n",
    "- Feel free to enrich the dataset with any additional information you consider useful: engineered features, external data, derived temporal features, etc.  \n",
    "- If the dataset is too large for your computer, use <code>.sample()</code> to work with a subset while preserving the logic of your pipeline.  \n",
    "- Plotly offers a wide variety of powerful visualizations, experiment creatively, but always begin with a clear analytical question: *What insight am I trying to uncover with this plot?*\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Submission Deadline:</b> Wednesday, December 3rd, 12:00\n",
    "\n",
    "Start with a simple, working pipeline.  \n",
    "Do not over-complicate your code too much. Start with a simple working solution and refine it if you have time.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "You may add as many cells as you want, but the **first cell must remain exactly as provided**. Do not edit, move, or delete it under any circumstances.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1da41098",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8431230dc8647851888c39d82eb7078d",
     "grade": true,
     "grade_id": "ex1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LEAVE BLANK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84467c34-1fa2-4f03-b7ba-e216836ff6b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bce797b7aa5f22189e671fd29fa5841",
     "grade": false,
     "grade_id": "cell-140b4c12d85796ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Team Information\n",
    "\n",
    "Fill in the information below.  \n",
    "All fields are **mandatory**.\n",
    "\n",
    "- **GitHub Repository URL**: Paste the link to the team repo you will use for collaboration.\n",
    "- **Team Members**: List all student names (and emails or IDs if required).\n",
    "\n",
    "Do not modify the section title.  \n",
    "Do not remove this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "907a430c-3e17-42e4-9b63-3bafd596c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('https://github.com/seanhoet65-source/hackathon_python',\n",
       " ['Pau Gratacós Fusté',\n",
       "  'Sean Hoet',\n",
       "  'Florian Nix',\n",
       "  'Caroline Wheeler',\n",
       "  'Riwad Irshied'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Team Information (Mandatory) ===\n",
    "# Fill in the fields below.\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/seanhoet65-source/hackathon_python\"\n",
    "TEAM_MEMBERS = [\"Pau Gratacós Fusté\", \"Sean Hoet\", \"Florian Nix\", \"Caroline Wheeler\", \"Riwad Irshied\"]\n",
    "\n",
    "GITHUB_REPO, TEAM_MEMBERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8779dddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: LOADING RAW DATA\n",
      "============================================================\n",
      "✓ Listings: 2,654 rows × 79 columns\n",
      "✓ Calendar: 968,710 rows × 7 columns\n",
      "✓ Reviews: 122,622 rows × 6 columns\n",
      "\n",
      "============================================================\n",
      "STEP 2: CLEANING LISTINGS DATA\n",
      "============================================================\n",
      "✓ Removed 357 listings with missing/invalid data\n",
      "✓ Clean listings: 2,297 rows\n",
      "\n",
      "============================================================\n",
      "STEP 3: CLEANING CALENDAR DATA\n",
      "============================================================\n",
      "✓ Removed 0 calendar entries with missing data\n",
      "✓ Clean calendar: 968,710 rows\n",
      "✓ Date range: 2025-06-25 00:00:00 to 2026-06-29 00:00:00\n",
      "\n",
      "============================================================\n",
      "STEP 4: CLEANING REVIEWS DATA\n",
      "============================================================\n",
      "✓ Removed 3,155 reviews with missing data\n",
      "✓ Clean reviews: 119,467 rows\n",
      "\n",
      "============================================================\n",
      "STEP 5: CREATING REVIEW FEATURES\n",
      "============================================================\n",
      "✓ Review features created for 2,222 listings\n",
      "\n",
      "Review features preview:\n",
      "   listing_id  review_count first_review_date last_review_date  \\\n",
      "0       50904             3        2015-05-06       2022-05-15   \n",
      "1      345959           128        2012-05-12       2025-06-19   \n",
      "2      366252           159        2012-03-29       2024-09-26   \n",
      "3      603545            45        2012-12-16       2024-11-08   \n",
      "4      772842            81        2013-01-04       2025-04-23   \n",
      "\n",
      "   days_since_first_review  days_since_last_review  review_period_days  \\\n",
      "0                     3862                    1296                2566   \n",
      "1                     4951                     165                4786   \n",
      "2                     4995                     431                4564   \n",
      "3                     4733                     388                4345   \n",
      "4                     4714                     222                4492   \n",
      "\n",
      "   reviews_per_month  \n",
      "0           0.035074  \n",
      "1           0.802340  \n",
      "2           1.045136  \n",
      "3           0.310702  \n",
      "4           0.540962  \n",
      "\n",
      "============================================================\n",
      "STEP 6: MERGING DATASETS\n",
      "============================================================\n",
      "✓ Calendar + Listings: 838,405 rows × 86 columns\n",
      "✓ Added review features: 838,405 rows × 93 columns\n",
      "\n",
      "============================================================\n",
      "STEP 7: FINAL DATA QUALITY CHECK\n",
      "============================================================\n",
      "\n",
      "Final dataset shape: 838,405 rows × 89 columns\n",
      "\n",
      "Target variable (available) distribution:\n",
      "available\n",
      "True     514883\n",
      "False    323522\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Missing values in key columns:\n",
      "available     0\n",
      "price         0\n",
      "listing_id    0\n",
      "date          0\n",
      "dtype: int64\n",
      "\n",
      "Top 10 columns with missing values:\n",
      "host_neighbourhood       828915\n",
      "host_about               480705\n",
      "neighborhood_overview    420480\n",
      "neighbourhood            420480\n",
      "host_location            227760\n",
      "reviews_per_month_y      133225\n",
      "first_review_date        133225\n",
      "last_review_date         133225\n",
      "reviews_per_month_x      132130\n",
      "first_review             132130\n",
      "dtype: int64\n",
      "\n",
      "============================================================\n",
      "✅ DATA LOADING, CLEANING & MERGING COMPLETE!\n",
      "============================================================\n",
      "Ready for EDA with 838,405 observations\n",
      "\n",
      "Sample of merged dataset:\n",
      "   listing_id       date  available  minimum_nights_cal  maximum_nights_cal  \\\n",
      "0       50904 2025-06-26       True                   1                1000   \n",
      "1       50904 2025-06-27      False                   1                1000   \n",
      "2       50904 2025-06-28      False                   1                1000   \n",
      "3       50904 2025-06-29      False                   1                1000   \n",
      "4       50904 2025-06-30       True                   1                1000   \n",
      "\n",
      "      id                         listing_url       scrape_id last_scraped  \\\n",
      "0  50904  https://www.airbnb.com/rooms/50904  20250625193541   2025-06-26   \n",
      "1  50904  https://www.airbnb.com/rooms/50904  20250625193541   2025-06-26   \n",
      "2  50904  https://www.airbnb.com/rooms/50904  20250625193541   2025-06-26   \n",
      "3  50904  https://www.airbnb.com/rooms/50904  20250625193541   2025-06-26   \n",
      "4  50904  https://www.airbnb.com/rooms/50904  20250625193541   2025-06-26   \n",
      "\n",
      "        source  ... calculated_host_listings_count_shared_rooms  \\\n",
      "0  city scrape  ...                                           0   \n",
      "1  city scrape  ...                                           0   \n",
      "2  city scrape  ...                                           0   \n",
      "3  city scrape  ...                                           0   \n",
      "4  city scrape  ...                                           0   \n",
      "\n",
      "  reviews_per_month_x review_count first_review_date  last_review_date  \\\n",
      "0                0.02          3.0        2015-05-06        2022-05-15   \n",
      "1                0.02          3.0        2015-05-06        2022-05-15   \n",
      "2                0.02          3.0        2015-05-06        2022-05-15   \n",
      "3                0.02          3.0        2015-05-06        2022-05-15   \n",
      "4                0.02          3.0        2015-05-06        2022-05-15   \n",
      "\n",
      "  days_since_first_review days_since_last_review review_period_days  \\\n",
      "0                  3862.0                 1296.0             2566.0   \n",
      "1                  3862.0                 1296.0             2566.0   \n",
      "2                  3862.0                 1296.0             2566.0   \n",
      "3                  3862.0                 1296.0             2566.0   \n",
      "4                  3862.0                 1296.0             2566.0   \n",
      "\n",
      "  reviews_per_month_y  price  \n",
      "0            0.035074  130.0  \n",
      "1            0.035074  130.0  \n",
      "2            0.035074  130.0  \n",
      "3            0.035074  130.0  \n",
      "4            0.035074  130.0  \n",
      "\n",
      "[5 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# ===== 1. LOAD THE RAW DATA =====\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: LOADING RAW DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Local paths\n",
    "listings_path = \"listings.csv.gz\"\n",
    "calendar_path = \"calendar.csv.gz\"\n",
    "reviews_path = \"reviews.csv.gz\"\n",
    "\n",
    "# Load datasets\n",
    "listings = pd.read_csv(listings_path)\n",
    "calendar = pd.read_csv(calendar_path)\n",
    "reviews = pd.read_csv(reviews_path)\n",
    "\n",
    "print(f\"✓ Listings: {listings.shape[0]:,} rows × {listings.shape[1]} columns\")\n",
    "print(f\"✓ Calendar: {calendar.shape[0]:,} rows × {calendar.shape[1]} columns\")\n",
    "print(f\"✓ Reviews: {reviews.shape[0]:,} rows × {reviews.shape[1]} columns\")\n",
    "\n",
    "# ===== 2. CLEAN LISTINGS DATA =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: CLEANING LISTINGS DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "original_listings = listings.shape[0]\n",
    "\n",
    "# Convert date columns\n",
    "if \"last_scraped\" in listings.columns:\n",
    "    listings[\"last_scraped\"] = pd.to_datetime(listings[\"last_scraped\"], errors=\"coerce\")\n",
    "if \"host_since\" in listings.columns:\n",
    "    listings[\"host_since\"] = pd.to_datetime(listings[\"host_since\"], errors=\"coerce\")\n",
    "\n",
    "# Clean price column from listings (this will be our main price signal)\n",
    "if \"price\" in listings.columns:\n",
    "    listings[\"price\"] = listings[\"price\"].replace(r\"[\\$,]\", \"\", regex=True)\n",
    "    listings[\"price\"] = pd.to_numeric(listings[\"price\"], errors=\"coerce\")\n",
    "\n",
    "# Convert boolean-like columns\n",
    "bool_mapping = {\"t\": True, \"f\": False, True: True, False: False}\n",
    "bool_cols = [\n",
    "    \"host_is_superhost\",\n",
    "    \"host_has_profile_pic\",\n",
    "    \"host_identity_verified\",\n",
    "    \"has_availability\",\n",
    "    \"instant_bookable\",\n",
    "]\n",
    "for col in bool_cols:\n",
    "    if col in listings.columns:\n",
    "        listings[col] = listings[col].map(bool_mapping)\n",
    "\n",
    "# Convert percentage-like columns\n",
    "numeric_cols = [\"host_response_rate\", \"host_acceptance_rate\"]\n",
    "for col in numeric_cols:\n",
    "    if col in listings.columns and listings[col].dtype == \"object\":\n",
    "        listings[col] = listings[col].str.rstrip(\"%\").astype(float) / 100\n",
    "\n",
    "# Remove listings with missing or invalid key info\n",
    "listings = listings.dropna(subset=[\"id\", \"price\"])\n",
    "listings = listings[listings[\"price\"] > 0]\n",
    "\n",
    "print(f\"✓ Removed {original_listings - listings.shape[0]:,} listings with missing/invalid data\")\n",
    "print(f\"✓ Clean listings: {listings.shape[0]:,} rows\")\n",
    "\n",
    "# ===== 3. CLEAN CALENDAR DATA =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: CLEANING CALENDAR DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "original_calendar = calendar.shape[0]\n",
    "\n",
    "# Convert date column\n",
    "calendar[\"date\"] = pd.to_datetime(calendar[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Try to clean price columns if they exist (may be all NaN in this dataset)\n",
    "for col in [\"price\", \"adjusted_price\"]:\n",
    "    if col in calendar.columns:\n",
    "        calendar[col] = calendar[col].replace(r\"[\\$,]\", \"\", regex=True)\n",
    "        calendar[col] = pd.to_numeric(calendar[col], errors=\"coerce\")\n",
    "\n",
    "# Convert available to boolean (target)\n",
    "if \"available\" in calendar.columns:\n",
    "    calendar[\"available\"] = calendar[\"available\"].map({\"t\": True, \"f\": False})\n",
    "\n",
    "# Remove rows with missing critical data\n",
    "calendar = calendar.dropna(subset=[\"listing_id\", \"date\", \"available\"])\n",
    "\n",
    "print(f\"✓ Removed {original_calendar - calendar.shape[0]:,} calendar entries with missing data\")\n",
    "print(f\"✓ Clean calendar: {calendar.shape[0]:,} rows\")\n",
    "print(f\"✓ Date range: {calendar['date'].min()} to {calendar['date'].max()}\")\n",
    "\n",
    "# ===== 4. CLEAN REVIEWS DATA =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 4: CLEANING REVIEWS DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "original_reviews = reviews.shape[0]\n",
    "\n",
    "# Convert date column\n",
    "reviews[\"date\"] = pd.to_datetime(reviews[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Remove rows with missing critical data\n",
    "reviews = reviews.dropna(subset=[\"listing_id\", \"date\"])\n",
    "\n",
    "# Remove reviews with no/very short text\n",
    "if \"comments\" in reviews.columns:\n",
    "    reviews = reviews.dropna(subset=[\"comments\"])\n",
    "    reviews = reviews[reviews[\"comments\"].str.len() > 10]\n",
    "\n",
    "print(f\"✓ Removed {original_reviews - reviews.shape[0]:,} reviews with missing data\")\n",
    "print(f\"✓ Clean reviews: {reviews.shape[0]:,} rows\")\n",
    "\n",
    "# ===== 5. AGGREGATE REVIEW FEATURES =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 5: CREATING REVIEW FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "review_features = (\n",
    "    reviews.groupby(\"listing_id\")\n",
    "    .agg(\n",
    "        {\n",
    "            \"id\": \"count\",          # total number of reviews\n",
    "            \"date\": [\"min\", \"max\"], # first and last review dates\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Flatten column names\n",
    "review_features.columns = [\n",
    "    \"listing_id\",\n",
    "    \"review_count\",\n",
    "    \"first_review_date\",\n",
    "    \"last_review_date\",\n",
    "]\n",
    "\n",
    "current_date = pd.Timestamp.now()\n",
    "review_features[\"days_since_first_review\"] = (\n",
    "    current_date - review_features[\"first_review_date\"]\n",
    ").dt.days\n",
    "review_features[\"days_since_last_review\"] = (\n",
    "    current_date - review_features[\"last_review_date\"]\n",
    ").dt.days\n",
    "review_features[\"review_period_days\"] = (\n",
    "    review_features[\"last_review_date\"] - review_features[\"first_review_date\"]\n",
    ").dt.days\n",
    "\n",
    "# Review rate (reviews per month)\n",
    "review_features[\"reviews_per_month\"] = (\n",
    "    review_features[\"review_count\"] / (review_features[\"review_period_days\"] / 30)\n",
    ")\n",
    "review_features[\"reviews_per_month\"] = review_features[\"reviews_per_month\"].fillna(0)\n",
    "\n",
    "print(f\"✓ Review features created for {review_features.shape[0]:,} listings\")\n",
    "print(\"\\nReview features preview:\")\n",
    "print(review_features.head())\n",
    "\n",
    "# ===== 6. MERGE DATASETS =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 6: MERGING DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Merge calendar with listings: base grain = (listing, date)\n",
    "df = calendar.merge(\n",
    "    listings,\n",
    "    left_on=\"listing_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"inner\",\n",
    "    suffixes=(\"_cal\", \"_listing\"),\n",
    ")\n",
    "print(f\"✓ Calendar + Listings: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "\n",
    "# Add review features\n",
    "df = df.merge(\n",
    "    review_features,\n",
    "    on=\"listing_id\",\n",
    "    how=\"left\",  # keep all listing-date rows even if no reviews\n",
    ")\n",
    "print(f\"✓ Added review features: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "\n",
    "# ===== 6b. UNIFY PRICE + BASIC CLEANUP =====\n",
    "\n",
    "# Create a single 'price' column:\n",
    "# Prefer calendar price if it exists and is non-null, otherwise use listing price.\n",
    "price_cal_col = \"price_cal\" if \"price_cal\" in df.columns else None\n",
    "price_listing_col = \"price_listing\" if \"price_listing\" in df.columns else None\n",
    "\n",
    "if price_cal_col and price_listing_col:\n",
    "    df[\"price\"] = df[price_cal_col].fillna(df[price_listing_col])\n",
    "elif price_listing_col:\n",
    "    df[\"price\"] = df[price_listing_col]\n",
    "elif price_cal_col:\n",
    "    df[\"price\"] = df[price_cal_col]\n",
    "else:\n",
    "    print(\"⚠ No price columns found after merge!\")\n",
    "\n",
    "# Drop clearly useless / fully missing columns if they exist\n",
    "cols_to_drop = [\n",
    "    \"price_cal\",\n",
    "    \"adjusted_price\",                 # all NaN in this scrape\n",
    "    \"license\",\n",
    "    \"neighbourhood_group_cleansed\",\n",
    "    \"calendar_updated\",\n",
    "]\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns])\n",
    "\n",
    "# Fill missing review-derived fields (no reviews → zeros)\n",
    "review_cols = [\n",
    "    \"review_count\",\n",
    "    \"days_since_first_review\",\n",
    "    \"days_since_last_review\",\n",
    "    \"review_period_days\",\n",
    "    \"reviews_per_month\",\n",
    "]\n",
    "for col in review_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# ===== 7. FINAL DATA QUALITY CHECK =====\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 7: FINAL DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\nTarget variable (available) distribution:\")\n",
    "print(df[\"available\"].value_counts())\n",
    "\n",
    "print(\"\\nMissing values in key columns:\")\n",
    "key_cols = [\"available\", \"price\", \"listing_id\", \"date\"]\n",
    "existing_key_cols = [c for c in key_cols if c in df.columns]\n",
    "missing_summary = df[existing_key_cols].isna().sum()\n",
    "print(missing_summary)\n",
    "\n",
    "print(\"\\nTop 10 columns with missing values:\")\n",
    "top_missing = df.isna().sum().sort_values(ascending=False).head(10)\n",
    "print(top_missing)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✅ DATA LOADING, CLEANING & MERGING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Ready for EDA with {df.shape[0]:,} observations\")\n",
    "\n",
    "print(\"\\nSample of merged dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4c47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    838405.000000\n",
       "mean        282.703091\n",
       "std        2579.411527\n",
       "min          13.000000\n",
       "25%          63.000000\n",
       "50%          88.000000\n",
       "75%         130.000000\n",
       "max       50000.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"price\"].describe()\n",
    "'''\n",
    "count      838,405   ← ✔️ every row has a price\n",
    "mean          282.7   ← ✔️ reasonable for Barcelona\n",
    "std          2579     ← ⚠️ huge → indicates some extreme outliers\n",
    "min            13     ← ✔️ normal low-end price\n",
    "25%            63     ← ✔️ budget listings\n",
    "50% (=median)  88     ← ✔️ central tendency\n",
    "75%           130     ← ✔️ typical Airbnb\n",
    "max         50,000    ← ⚠️ extreme outliers\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2469098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
